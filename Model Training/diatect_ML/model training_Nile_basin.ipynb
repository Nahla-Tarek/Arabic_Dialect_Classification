{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7da558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a46068",
   "metadata": {},
   "source": [
    "### Import excel file for nile basin countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6cec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"data_nile_basin.xlsx\",index_col=0,\n",
    "              dtype={'tokens': str, 'dialect': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b526855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244697</th>\n",
       "      <td>الاقيش معاك الف يا عم نجيب قرض حسن ابدا بيهم ح...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244698</th>\n",
       "      <td>انت بتفهم كنت بقيت زملكاوي</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244699</th>\n",
       "      <td>ولولوا وسكتوا</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244700</th>\n",
       "      <td>واحده عشان بواب ملكش عازه</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244701</th>\n",
       "      <td>جنسيتك ايه ده انت صهيوني مش هتقول كده</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405604</th>\n",
       "      <td>الناس دي بتنفخ قربه مقدوده بالدارجي كده البلد ...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405605</th>\n",
       "      <td>انت عايش وين بره السودان شنو ماشايف البحصل دا</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405606</th>\n",
       "      <td>مااحرم ميسي حريف ولعاب برضو مدريدي وافتخر</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405607</th>\n",
       "      <td>ياخي ديل ماخلو للشيطان وإبليس شي يروحو وين ربن...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405608</th>\n",
       "      <td>النبي صدمتني ياخي عاوز تعويض</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72018 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens dialect\n",
       "244697  الاقيش معاك الف يا عم نجيب قرض حسن ابدا بيهم ح...      EG\n",
       "244698                         انت بتفهم كنت بقيت زملكاوي      EG\n",
       "244699                                      ولولوا وسكتوا      EG\n",
       "244700                          واحده عشان بواب ملكش عازه      EG\n",
       "244701              جنسيتك ايه ده انت صهيوني مش هتقول كده      EG\n",
       "...                                                   ...     ...\n",
       "405604  الناس دي بتنفخ قربه مقدوده بالدارجي كده البلد ...      SD\n",
       "405605      انت عايش وين بره السودان شنو ماشايف البحصل دا      SD\n",
       "405606          مااحرم ميسي حريف ولعاب برضو مدريدي وافتخر      SD\n",
       "405607  ياخي ديل ماخلو للشيطان وإبليس شي يروحو وين ربن...      SD\n",
       "405608                       النبي صدمتني ياخي عاوز تعويض      SD\n",
       "\n",
       "[72018 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad8ac1",
   "metadata": {},
   "source": [
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94039e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens     0\n",
       "dialect    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ddb70b",
   "metadata": {},
   "source": [
    "### Building voting classifier (linearsvc, multinomialNB, BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7803767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_estimators():\n",
    "    estimators = []\n",
    "    svc = LinearSVC(penalty='l1', dual=False,tol=1e-6)\n",
    "    estimators.append(('svc',svc))\n",
    "    mnb= MultinomialNB(alpha=.01)\n",
    "    estimators.append(('mnb',mnb))\n",
    "    bnb= BernoulliNB(alpha=.01)\n",
    "    estimators.append(('bnb',bnb))\n",
    "    ensemble = VotingClassifier(estimators)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7578af",
   "metadata": {},
   "source": [
    "### train, validation,test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8189d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['tokens']\n",
    "y=df['dialect']\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.1,stratify=y,random_state=42)\n",
    "X_train1, X_valid, y_train1, y_valid=train_test_split(X_train, y_train,test_size=0.1,stratify=y_train,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afbd28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=list(y_train1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb71fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureunion -> combines several transformer objects into a new transformer that combines their output. \n",
    "# A FeatureUnion takes a list of transformer objects. During fitting, each of these is fit to the data independently.\n",
    "# For transforming data, the transformers are applied in parallel, and \n",
    "# the sample vectors they output are concatenated end-to-end into larger vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef9053",
   "metadata": {},
   "source": [
    "### Extracting features from the training data using a Tfidf-vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deadf8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "Combined space has 1619119 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "# featureunion -> concatenate the results of multiple transformer objects,combine several feature extraction mechanisms\n",
    "#into a single transformer.\n",
    "max_df = 0.5\n",
    "union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=max_df,analyzer = 'word', ngram_range=(1,3)\n",
    "                                 )),\n",
    "                       (\"c_wb\", TfidfVectorizer(sublinear_tf=True,max_df=max_df,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                 )),\n",
    "\n",
    "                      (\"c_wb5\", TfidfVectorizer(sublinear_tf=True, max_df=max_df,analyzer = 'char', ngram_range=(2,4)\n",
    "                                 )),\n",
    "                      \n",
    "\n",
    "                       ],\n",
    "transformer_weights={\n",
    "           'w_v': 0.9,\n",
    "         \n",
    "            'c_wb': 0.9,\n",
    "         \n",
    "           \"c_wb5\":0.9,\n",
    "        }\n",
    ",\n",
    ")\n",
    "\n",
    "\n",
    "X_train_feat = union.fit_transform(X_train1)\n",
    "X_valid_feat = union.transform(X_valid)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_feat, y_train1)\n",
    "print(\"Combined space has\", X_res.shape[1], \"features\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269f1ed",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              LinearSVC(dual=False, penalty='l1', tol=1e-06)),\n",
       "                             ('mnb', MultinomialNB(alpha=0.01)),\n",
       "                             ('bnb', BernoulliNB(alpha=0.01))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ensemble = build_estimators()\n",
    "ensemble.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f6bc4",
   "metadata": {},
   "source": [
    "### Testing the classifier on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a518e2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.932\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          SD       0.94      0.98      0.96      5186\n",
      "          EG       0.89      0.75      0.82      1296\n",
      "\n",
      "    accuracy                           0.93      6482\n",
      "   macro avg       0.91      0.86      0.89      6482\n",
      "weighted avg       0.93      0.93      0.93      6482\n",
      "\n",
      "confusion matrix:\n",
      "[[5064  122]\n",
      " [ 320  976]]\n"
     ]
    }
   ],
   "source": [
    "pred = ensemble.predict(X_valid_feat)\n",
    "score = metrics.accuracy_score(y_valid, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_valid, pred,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27e547",
   "metadata": {},
   "source": [
    "### Testing the classifier on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886f24e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.930\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          SD       0.94      0.98      0.96      5762\n",
      "          EG       0.88      0.75      0.81      1440\n",
      "\n",
      "    accuracy                           0.93      7202\n",
      "   macro avg       0.91      0.86      0.88      7202\n",
      "weighted avg       0.93      0.93      0.93      7202\n",
      "\n",
      "confusion matrix:\n",
      "[[5618  144]\n",
      " [ 357 1083]]\n"
     ]
    }
   ],
   "source": [
    "X_test_feat = union.transform(X_test)\n",
    "pred_test=ensemble.predict(X_test_feat)\n",
    "score = metrics.accuracy_score(y_test, pred_test)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_test, pred_test,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d717663",
   "metadata": {},
   "source": [
    "### Testing the model on some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13b13c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EG'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ensemble.predict(union.transform([\"انا كويسة الحمد لله\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f6ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SD'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(union.transform([\"اهلا زول\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "151d3da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.998\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          SD       1.00      1.00      1.00     46673\n",
      "          EG       1.00      1.00      1.00     11661\n",
      "\n",
      "    accuracy                           1.00     58334\n",
      "   macro avg       1.00      1.00      1.00     58334\n",
      "weighted avg       1.00      1.00      1.00     58334\n",
      "\n",
      "confusion matrix:\n",
      "[[46617    56]\n",
      " [   48 11613]]\n"
     ]
    }
   ],
   "source": [
    "p=ensemble.predict(X_train_feat)\n",
    "score=metrics.accuracy_score(y_train1, p)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_train1, p,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_train1, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a8bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ensemble,open('model_nile_basin.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f85caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(union,open('union_nile_basin.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f947bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
