{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7da558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec13e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410371e",
   "metadata": {},
   "source": [
    "### Import excel file for gulf countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6cec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"data_gulf.xlsx\",index_col=0,\n",
    "              dtype={'tokens': str, 'dialect': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b526855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51996</th>\n",
       "      <td>شفتك حاط صوره ولد النعاشه النجس وانا غاسل يدي ...</td>\n",
       "      <td>QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51997</th>\n",
       "      <td>محد داس طرف يالذنب وش جابك تغريده لتاج راسك تم...</td>\n",
       "      <td>QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51998</th>\n",
       "      <td>وين انت رايح يابن حجيلان التزم الصمت لان ملك ا...</td>\n",
       "      <td>QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51999</th>\n",
       "      <td>ياخي انت ماتتوب انا قايلك اشوفك بتغريده تخص شي...</td>\n",
       "      <td>QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52000</th>\n",
       "      <td>قلتها يالسلوقي الف مره لاكن الانجاس ماتتوب عدت...</td>\n",
       "      <td>QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>مبسوطين اللي باسطانا</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>ماينده ابش يختي</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>شو عملنا حنا تهربي احنا مساكين ليش بتعملي هيك</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>الله يبارك وبالعافيه</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>السحله ضيفي بتطلع سحليه</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens dialect\n",
       "51996   شفتك حاط صوره ولد النعاشه النجس وانا غاسل يدي ...      QA\n",
       "51997   محد داس طرف يالذنب وش جابك تغريده لتاج راسك تم...      QA\n",
       "51998   وين انت رايح يابن حجيلان التزم الصمت لان ملك ا...      QA\n",
       "51999   ياخي انت ماتتوب انا قايلك اشوفك بتغريده تخص شي...      QA\n",
       "52000   قلتها يالسلوقي الف مره لاكن الانجاس ماتتوب عدت...      QA\n",
       "...                                                   ...     ...\n",
       "458192                               مبسوطين اللي باسطانا      BH\n",
       "458193                                    ماينده ابش يختي      BH\n",
       "458194      شو عملنا حنا تهربي احنا مساكين ليش بتعملي هيك      BH\n",
       "458195                               الله يبارك وبالعافيه      BH\n",
       "458196                            السحله ضيفي بتطلع سحليه      BH\n",
       "\n",
       "[171684 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37790753",
   "metadata": {},
   "source": [
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94039e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens     0\n",
       "dialect    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5be2ea",
   "metadata": {},
   "source": [
    "### Building voting classifier (linearsvc, multinomialNB, BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7803767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_estimators():\n",
    "    estimators = []\n",
    "#     Ridge = RidgeClassifier(alpha=0.00001, max_iter=70) \n",
    "#     estimators.append(('Ridge',Ridge))\n",
    "    svc = LinearSVC(penalty='l1', dual=False,tol=1e-3)\n",
    "    estimators.append(('svc',svc))\n",
    "    mnb= MultinomialNB(alpha=.01)\n",
    "    estimators.append(('mnb',mnb))\n",
    "    bnb= BernoulliNB(alpha=.01)\n",
    "    estimators.append(('bnb',bnb))\n",
    "    ensemble = VotingClassifier(estimators)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968f703",
   "metadata": {},
   "source": [
    "### train, validation,test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8189d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['tokens']\n",
    "y=df['dialect']\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.1,stratify=y,random_state=42)\n",
    "X_train1, X_valid, y_train1, y_valid=train_test_split(X_train, y_train,test_size=0.1,stratify=y_train,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbd28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=list(y_train1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb71fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureunion -> combines several transformer objects into a new transformer that combines their output. \n",
    "# A FeatureUnion takes a list of transformer objects. During fitting, each of these is fit to the data independently.\n",
    "# For transforming data, the transformers are applied in parallel, and \n",
    "# the sample vectors they output are concatenated end-to-end into larger vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deda2b6",
   "metadata": {},
   "source": [
    "### Extracting features from the training data using a Tfidf-vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deadf8e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined space has 3121458 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# featureunion -> concatenate the results of multiple transformer objects,combine several feature extraction mechanisms\n",
    "#into a single transformer.\n",
    "max_df = 0.5\n",
    "union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=max_df,analyzer = 'word', ngram_range=(1,3)\n",
    "                                 )),\n",
    "\n",
    "                       (\"c_wb\", TfidfVectorizer(sublinear_tf=True,max_df=max_df,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                                 )),\n",
    "\n",
    "                    (\"c_wb5\", TfidfVectorizer(sublinear_tf=True, max_df=max_df,analyzer = 'char', ngram_range=(2,4)\n",
    "                               )),\n",
    "\n",
    "                       ],\n",
    "transformer_weights={\n",
    "            'w_v': 0.9,\n",
    "\n",
    "            'c_wb': 0.9,\n",
    "\n",
    "          \"c_wb5\":0.9,\n",
    "           \n",
    "        }\n",
    ",\n",
    ")\n",
    "\n",
    "X_train_feat = union.fit_transform(X_train1)\n",
    "X_valid_feat = union.transform(X_valid)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_feat, y_train1)\n",
    "print(\"Combined space has\", X_res.shape[1], \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93c29f",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a3c106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              LinearSVC(dual=False, penalty='l1', tol=0.001)),\n",
       "                             ('mnb', MultinomialNB(alpha=0.01)),\n",
       "                             ('bnb', BernoulliNB(alpha=0.01))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble=build_estimators()\n",
    "ensemble.fit(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d9cd0",
   "metadata": {},
   "source": [
    "### Testing the classifier on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3a14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.523\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          SA       0.47      0.53      0.50      2366\n",
      "          BH       0.37      0.53      0.44      2366\n",
      "          QA       0.61      0.59      0.60      3789\n",
      "          AE       0.51      0.45      0.48      1720\n",
      "          OM       0.61      0.49      0.54      2796\n",
      "          KW       0.60      0.50      0.54      2415\n",
      "\n",
      "    accuracy                           0.52     15452\n",
      "   macro avg       0.53      0.51      0.52     15452\n",
      "weighted avg       0.54      0.52      0.53     15452\n",
      "\n",
      "confusion matrix:\n",
      "[[1261  341  227  191  216  130]\n",
      " [ 266 1246  394  149  175  136]\n",
      " [ 331  654 2231  124  210  239]\n",
      " [ 255  305  177  769   84  130]\n",
      " [ 325  442  346  128 1370  185]\n",
      " [ 227  358  292  149  179 1210]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = ensemble.predict(X_valid_feat)\n",
    "\n",
    "score = metrics.accuracy_score(y_valid, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_valid, pred,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de3f69",
   "metadata": {},
   "source": [
    "### Testing the classifier on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886f24e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.524\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          SA       0.47      0.55      0.51      2629\n",
      "          BH       0.37      0.50      0.43      2629\n",
      "          QA       0.61      0.58      0.60      4210\n",
      "          AE       0.49      0.46      0.47      1911\n",
      "          OM       0.62      0.51      0.56      3107\n",
      "          KW       0.60      0.49      0.54      2683\n",
      "\n",
      "    accuracy                           0.52     17169\n",
      "   macro avg       0.53      0.52      0.52     17169\n",
      "weighted avg       0.54      0.52      0.53     17169\n",
      "\n",
      "confusion matrix:\n",
      "[[1437  322  255  243  221  151]\n",
      " [ 346 1312  420  164  244  143]\n",
      " [ 324  719 2455  177  249  286]\n",
      " [ 330  337  175  880   77  112]\n",
      " [ 336  439  370  174 1585  203]\n",
      " [ 269  387  346  165  194 1322]]\n"
     ]
    }
   ],
   "source": [
    "X_test_feat = union.transform(X_test)\n",
    "pred_test=ensemble.predict(X_test_feat)\n",
    "score = metrics.accuracy_score(y_test, pred_test)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_test, pred_test,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f4501",
   "metadata": {},
   "source": [
    "### Testing the model on some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13b13c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AE'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ensemble.predict(union.transform([\"اشحالك\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a841fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BH'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(union.transform([\"بزبوز\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57e61f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SA'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(union.transform([\"السحله\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f012862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SA'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(union.transform([\"مرهلاكن\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e987df84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SA'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(union.transform([\"السواه\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7605404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ensemble,open('model_gulf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab7ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(union,open('union_gulf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65108c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
