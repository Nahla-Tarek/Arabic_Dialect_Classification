{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2dbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca174b3b",
   "metadata": {},
   "source": [
    "### Import excel file for the main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec39d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"data_main.xlsx\",index_col=0,\n",
    "              dtype={'tokens': str, 'dialect': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe11bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بالنهايه ينتفض يغير</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مبين كلامه خليجي</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وين الغيبه اخ محمد</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>مبسوطين اللي باسطانا</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>ماينده ابش يختي</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>شو عملنا حنا تهربي احنا مساكين ليش بتعملي هيك</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>الله يبارك وبالعافيه</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>السحله ضيفي بتطلع سحليه</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens dialect\n",
       "0                                     بالنهايه ينتفض يغير      IQ\n",
       "1       يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يح...      IQ\n",
       "2                                        مبين كلامه خليجي      IQ\n",
       "3                               يسلملي مرورك وروحك الحلوه      IQ\n",
       "4                                      وين الغيبه اخ محمد      IQ\n",
       "...                                                   ...     ...\n",
       "458192                               مبسوطين اللي باسطانا    GULF\n",
       "458193                                    ماينده ابش يختي    GULF\n",
       "458194      شو عملنا حنا تهربي احنا مساكين ليش بتعملي هيك    GULF\n",
       "458195                               الله يبارك وبالعافيه    GULF\n",
       "458196                            السحله ضيفي بتطلع سحليه    GULF\n",
       "\n",
       "[458040 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c7b79",
   "metadata": {},
   "source": [
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922a552c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens     0\n",
       "dialect    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be3c82",
   "metadata": {},
   "source": [
    "### Building voting classifier (linearsvc, multinomialNB, BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d5dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_estimators():\n",
    "    estimators = []\n",
    "    svc = LinearSVC(penalty='l1', dual=False,tol=1e-3)\n",
    "    estimators.append(('svc',svc))\n",
    "    mnb= MultinomialNB(alpha=.01)\n",
    "    estimators.append(('mnb',mnb))\n",
    "    bnb= BernoulliNB(alpha=.01)\n",
    "    estimators.append(('bnb',bnb))\n",
    "    ensemble = VotingClassifier(estimators)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402a7f4",
   "metadata": {},
   "source": [
    "### train, validation,test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8189d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['tokens']\n",
    "y=df['dialect']\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.1,stratify=y,random_state=42)\n",
    "X_train1, X_valid, y_train1, y_valid=train_test_split(X_train, y_train,test_size=0.1,stratify=y_train,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349fc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=list(y_train1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff223543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureunion -> combines several transformer objects into a new transformer that combines their output. \n",
    "# A FeatureUnion takes a list of transformer objects. During fitting, each of these is fit to the data independently.\n",
    "# For transforming data, the transformers are applied in parallel, and \n",
    "# the sample vectors they output are concatenated end-to-end into larger vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7fa33",
   "metadata": {},
   "source": [
    "### Extracting features from the training data using a Tfidf-Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ac4f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined space has 8231413 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# featureunion -> concatenate the results of multiple transformer objects,combine several feature extraction mechanisms\n",
    "#into a single transformer.\n",
    "max_df = 0.5\n",
    "union = FeatureUnion([(\"w_v\", TfidfVectorizer(sublinear_tf=True, max_df=max_df,analyzer = 'word', ngram_range=(1,3)\n",
    "                                             )),\n",
    "\n",
    "                      (\"c_wb\", TfidfVectorizer(sublinear_tf=True,max_df=max_df,analyzer = 'char_wb', ngram_range=(2,5)\n",
    "                              )),\n",
    " \n",
    "                      (\"c_wb5\", TfidfVectorizer(sublinear_tf=True, max_df=max_df,analyzer = 'char', ngram_range=(2,5)\n",
    "                                 )),\n",
    "                     \n",
    "\n",
    "                       ],\n",
    "transformer_weights={\n",
    "            'w_v': 0.9,\n",
    "            'c_wb': 0.9,\n",
    "          \"c_wb5\":0.9,\n",
    "           \n",
    "        }\n",
    ",\n",
    ")\n",
    "\n",
    "X_train_feat = union.fit_transform(X_train1)\n",
    "X_valid_feat = union.transform(X_valid)\n",
    "sm = SMOTE(random_state=42)              ## to solve the imbalanced data problem\n",
    "X_res, y_res = sm.fit_resample(X_train_feat, y_train1)\n",
    "print(\"Combined space has\", X_res.shape[1], \"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfe265",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87bb5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              LinearSVC(dual=False, penalty='l1', tol=0.001)),\n",
       "                             ('mnb', MultinomialNB(alpha=0.01)),\n",
       "                             ('bnb', BernoulliNB(alpha=0.01))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ensemble = build_estimators()\n",
    "ensemble.fit(X_res, y_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539f910",
   "metadata": {},
   "source": [
    "### Testing the classifier on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b1f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.794\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      LEVANT       0.78      0.89      0.83     15452\n",
      "        GULF       0.74      0.47      0.57      1394\n",
      "  NILE BASIN       0.77      0.80      0.78     10394\n",
      "     MAGHERB       0.84      0.71      0.77      6610\n",
      "          YE       0.85      0.80      0.82      6481\n",
      "          IQ       0.50      0.14      0.22       893\n",
      "\n",
      "    accuracy                           0.79     41224\n",
      "   macro avg       0.75      0.63      0.67     41224\n",
      "weighted avg       0.79      0.79      0.79     41224\n",
      "\n",
      "confusion matrix:\n",
      "[[13741   108   967   343   215    78]\n",
      " [  529   649   148    48    17     3]\n",
      " [ 1368    57  8322   271   358    18]\n",
      " [  921    37   647  4666   317    22]\n",
      " [  462    18   580   201  5215     5]\n",
      " [  525     9   145    49    40   125]]\n"
     ]
    }
   ],
   "source": [
    "pred = ensemble.predict(X_valid_feat)\n",
    "#for i in range(0,10):\n",
    " #   print(data_train.target_names[pred[i]])\n",
    "\n",
    "score = metrics.accuracy_score(y_valid, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_valid, pred,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6adb452",
   "metadata": {},
   "source": [
    "### Testing the classifier on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0301d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.791\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      LEVANT       0.79      0.89      0.83     17168\n",
      "        GULF       0.74      0.49      0.59      1549\n",
      "  NILE BASIN       0.77      0.80      0.78     11549\n",
      "     MAGHERB       0.82      0.69      0.75      7344\n",
      "          YE       0.84      0.80      0.82      7202\n",
      "          IQ       0.52      0.17      0.25       992\n",
      "\n",
      "    accuracy                           0.79     45804\n",
      "   macro avg       0.74      0.64      0.67     45804\n",
      "weighted avg       0.79      0.79      0.78     45804\n",
      "\n",
      "confusion matrix:\n",
      "[[15244   125  1083   422   209    85]\n",
      " [  567   756   148    52    19     7]\n",
      " [ 1432    52  9232   344   461    28]\n",
      " [ 1046    52   747  5076   399    24]\n",
      " [  515    20   665   245  5744    13]\n",
      " [  551    14   166    54    40   167]]\n"
     ]
    }
   ],
   "source": [
    "X_test_feat = union.transform(X_test)\n",
    "pred_test=ensemble.predict(X_test_feat)\n",
    "score = metrics.accuracy_score(y_test, pred_test)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_test, pred_test,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1c56f",
   "metadata": {},
   "source": [
    "### Testing the model on some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a47f515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MAGHERB'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ensemble.predict(union.transform([\"المعلومه غلط انا ماشفتك الا ورى\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9045124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LEVANT'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(union.transform([\"معنعن\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1871c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.980\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      LEVANT       0.98      0.98      0.98    139064\n",
      "        GULF       0.98      1.00      0.99     12547\n",
      "  NILE BASIN       0.97      0.98      0.98     93543\n",
      "     MAGHERB       0.99      0.97      0.98     59488\n",
      "          YE       0.98      0.97      0.98     58335\n",
      "          IQ       0.98      1.00      0.99      8035\n",
      "\n",
      "    accuracy                           0.98    371012\n",
      "   macro avg       0.98      0.98      0.98    371012\n",
      "weighted avg       0.98      0.98      0.98    371012\n",
      "\n",
      "confusion matrix:\n",
      "[[136743    115   1161    396    554     95]\n",
      " [     8  12505     14      6      9      5]\n",
      " [  1242     50  91538    196    468     49]\n",
      " [   605     50    647  57820    340     26]\n",
      " [   688     44    571    146  56874     12]\n",
      " [     6      4     14      3      4   8004]]\n"
     ]
    }
   ],
   "source": [
    "p=ensemble.predict(X_train_feat)\n",
    "score=metrics.accuracy_score(y_train1, p)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(metrics.classification_report(y_train1, p,target_names=target_names))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_train1, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63cd60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ensemble,open('model_main.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daeb6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(union,open('union_main.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1856b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
