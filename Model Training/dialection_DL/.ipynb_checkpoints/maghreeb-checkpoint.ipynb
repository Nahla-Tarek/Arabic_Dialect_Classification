{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:24.306906Z",
     "iopub.status.busy": "2022-03-13T19:42:24.306451Z",
     "iopub.status.idle": "2022-03-13T19:42:34.489274Z",
     "shell.execute_reply": "2022-03-13T19:42:34.488241Z",
     "shell.execute_reply.started": "2022-03-13T19:42:24.306771Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:34.491876Z",
     "iopub.status.busy": "2022-03-13T19:42:34.491395Z",
     "iopub.status.idle": "2022-03-13T19:42:40.508262Z",
     "shell.execute_reply": "2022-03-13T19:42:40.507550Z",
     "shell.execute_reply.started": "2022-03-13T19:42:34.491833Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import fasttext\n",
    "from nltk.util import ngrams\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,GRU,LSTM,Bidirectional,Dropout,Conv1D,MaxPooling1D,GlobalAveragePooling1D,Flatten,Input\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from gensim.models import word2vec\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import excel file for maghreb countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:40.509674Z",
     "iopub.status.busy": "2022-03-13T19:42:40.509423Z",
     "iopub.status.idle": "2022-03-13T19:42:47.212393Z",
     "shell.execute_reply": "2022-03-13T19:42:47.211642Z",
     "shell.execute_reply.started": "2022-03-13T19:42:40.509641Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"../input/data-arabic-dialect/data_maghreb.xlsx\",index_col=0,\n",
    "              dtype={'tokens': str, 'dialect': str})\n",
    "## check the presence of null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.214956Z",
     "iopub.status.busy": "2022-03-13T19:42:47.214322Z",
     "iopub.status.idle": "2022-03-13T19:42:47.231935Z",
     "shell.execute_reply": "2022-03-13T19:42:47.231197Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.214915Z"
    }
   },
   "outputs": [],
   "source": [
    "## reset index\n",
    "df=df.reset_index()\n",
    "df.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count numbers of sentences that belong to each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.233647Z",
     "iopub.status.busy": "2022-03-13T19:42:47.233262Z",
     "iopub.status.idle": "2022-03-13T19:42:47.531201Z",
     "shell.execute_reply": "2022-03-13T19:42:47.530526Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.233605Z"
    }
   },
   "outputs": [],
   "source": [
    "x=df['dialect'].value_counts()\n",
    "print(x.index)\n",
    "sns.barplot(x.index,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute the max number of words ( max_length of the sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.532602Z",
     "iopub.status.busy": "2022-03-13T19:42:47.532257Z",
     "iopub.status.idle": "2022-03-13T19:42:47.536497Z",
     "shell.execute_reply": "2022-03-13T19:42:47.535741Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.532568Z"
    }
   },
   "outputs": [],
   "source": [
    "def splitolist(data):\n",
    "    l=data.split(\" \")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.538169Z",
     "iopub.status.busy": "2022-03-13T19:42:47.537729Z",
     "iopub.status.idle": "2022-03-13T19:42:47.734192Z",
     "shell.execute_reply": "2022-03-13T19:42:47.733397Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.538136Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tokens1']=df['tokens'].apply(splitolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.738727Z",
     "iopub.status.busy": "2022-03-13T19:42:47.738345Z",
     "iopub.status.idle": "2022-03-13T19:42:47.820347Z",
     "shell.execute_reply": "2022-03-13T19:42:47.819657Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.738692Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length=df.tokens1.str.len().max()\n",
    "print(\"max length is\"+\" \"+str(max_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.824917Z",
     "iopub.status.busy": "2022-03-13T19:42:47.824518Z",
     "iopub.status.idle": "2022-03-13T19:42:47.845064Z",
     "shell.execute_reply": "2022-03-13T19:42:47.844405Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.824880Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[0,['tokens','dialect']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a corpus of the entire dataset in a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:47.852584Z",
     "iopub.status.busy": "2022-03-13T19:42:47.852213Z",
     "iopub.status.idle": "2022-03-13T19:42:48.990876Z",
     "shell.execute_reply": "2022-03-13T19:42:48.990132Z",
     "shell.execute_reply.started": "2022-03-13T19:42:47.852549Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r'./corpus.txt', 'w', encoding='utf-8') as txtfile:\n",
    "    for i in range(len(df)):\n",
    "        line = df.loc[i,'tokens']\n",
    "        txtfile.write(line)\n",
    "        txtfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train skipgram model on the corpus to get word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:42:48.992390Z",
     "iopub.status.busy": "2022-03-13T19:42:48.992157Z",
     "iopub.status.idle": "2022-03-13T19:44:22.103017Z",
     "shell.execute_reply": "2022-03-13T19:44:22.102242Z",
     "shell.execute_reply.started": "2022-03-13T19:42:48.992357Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE=100\n",
    "model = fasttext.train_unsupervised('./corpus.txt',\n",
    "                                    minCount = 5, \n",
    "                                    model='skipgram',\n",
    "                                    minn = 2,\n",
    "                                    maxn = 5,\n",
    "                                    dim = 100,\n",
    "                                    lr = 0.1,\n",
    "                                    epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:44:22.105954Z",
     "iopub.status.busy": "2022-03-13T19:44:22.104423Z",
     "iopub.status.idle": "2022-03-13T19:44:22.416602Z",
     "shell.execute_reply": "2022-03-13T19:44:22.415835Z",
     "shell.execute_reply.started": "2022-03-13T19:44:22.105911Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a list of all unique words in the dataset\n",
    "with open(r'./corpus.txt', 'r', encoding=\"utf-8\") as txtfile:\n",
    "    corpus_sentences = txtfile.readlines()\n",
    "    corpus_words = []\n",
    "    for sent in corpus_sentences:\n",
    "        tokenized_sent = sent.split()\n",
    "        for word_ in tokenized_sent:\n",
    "            corpus_words.append(word_)\n",
    "            \n",
    "    corpus_unique_words = list(set(corpus_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert text to numbers using tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:44:22.418270Z",
     "iopub.status.busy": "2022-03-13T19:44:22.417964Z",
     "iopub.status.idle": "2022-03-13T19:44:25.638330Z",
     "shell.execute_reply": "2022-03-13T19:44:25.637588Z",
     "shell.execute_reply.started": "2022-03-13T19:44:22.418232Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(corpus_unique_words)+1)\n",
    "tokenizer.fit_on_texts(df['tokens'])\n",
    "sequences = tokenizer.texts_to_sequences(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:44:25.640015Z",
     "iopub.status.busy": "2022-03-13T19:44:25.639715Z",
     "iopub.status.idle": "2022-03-13T19:44:26.012978Z",
     "shell.execute_reply": "2022-03-13T19:44:26.012208Z",
     "shell.execute_reply.started": "2022-03-13T19:44:25.639969Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=max_length,padding='post')  ## padding all the sentences in the dataset to have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create embedding matrix from the trained fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:44:26.014633Z",
     "iopub.status.busy": "2022-03-13T19:44:26.014402Z",
     "iopub.status.idle": "2022-03-13T19:44:28.131823Z",
     "shell.execute_reply": "2022-03-13T19:44:28.131106Z",
     "shell.execute_reply.started": "2022-03-13T19:44:26.014599Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "embeddings_matrix = np.zeros(shape = (vocab_size , EMBED_SIZE))\n",
    "\n",
    "for word, index in tqdm(tokenizer.word_index.items()):\n",
    "    embeddings_matrix[index] = model.get_word_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:44:28.133747Z",
     "iopub.status.busy": "2022-03-13T19:44:28.133277Z",
     "iopub.status.idle": "2022-03-13T19:44:28.146849Z",
     "shell.execute_reply": "2022-03-13T19:44:28.146187Z",
     "shell.execute_reply.started": "2022-03-13T19:44:28.133708Z"
    }
   },
   "outputs": [],
   "source": [
    "data_y=pd.get_dummies(df['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:44:28.148442Z",
     "iopub.status.busy": "2022-03-13T19:44:28.148180Z",
     "iopub.status.idle": "2022-03-13T19:44:28.162419Z",
     "shell.execute_reply": "2022-03-13T19:44:28.161694Z",
     "shell.execute_reply.started": "2022-03-13T19:44:28.148403Z"
    }
   },
   "outputs": [],
   "source": [
    "data_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:50:57.418345Z",
     "iopub.status.busy": "2022-03-13T19:50:57.417678Z",
     "iopub.status.idle": "2022-03-13T19:50:58.043823Z",
     "shell.execute_reply": "2022-03-13T19:50:58.043056Z",
     "shell.execute_reply.started": "2022-03-13T19:50:57.418294Z"
    }
   },
   "outputs": [],
   "source": [
    "#split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,data_y, test_size = 0.1, stratify =data_y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:50:59.437356Z",
     "iopub.status.busy": "2022-03-13T19:50:59.437104Z",
     "iopub.status.idle": "2022-03-13T19:51:00.016074Z",
     "shell.execute_reply": "2022-03-13T19:51:00.015341Z",
     "shell.execute_reply.started": "2022-03-13T19:50:59.437328Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a bidirectional LSTM model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_size, EMBED_SIZE, \n",
    "                                weights=[embeddings_matrix], \n",
    "                                input_length=max_length , \n",
    "                                trainable=True)\n",
    "    \n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5000, activation='relu'))\n",
    "    model.add(Dense(len(np.unique(df['dialect'])), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model1 = create_model()\n",
    "tf.keras.backend.clear_session()\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss',mode = 'max',patience=3,verbose=1) #,mode = 'min',callbacks=[early_stop]\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=2)\n",
    "tf.keras.backend.clear_session()\n",
    "# early_stopping = EarlyStopping(monitor= 'val_acc', \n",
    "#                                mode = 'max',\n",
    "#                                patience=30, \n",
    "#                                verbose=1)\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint('levant_dialect_CLASSIFIER',\n",
    "#                                    monitor = 'val_acc', \n",
    "#                                    mode = 'max', \n",
    "#                                    save_best_only=True, \n",
    "#                                    verbose=1)\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate = 0.0001)\n",
    "\n",
    "model1.compile(opt, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:51:03.880377Z",
     "iopub.status.busy": "2022-03-13T19:51:03.879841Z",
     "iopub.status.idle": "2022-03-13T19:51:03.947250Z",
     "shell.execute_reply": "2022-03-13T19:51:03.945839Z",
     "shell.execute_reply.started": "2022-03-13T19:51:03.880340Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(df['dialect']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:51:05.499257Z",
     "iopub.status.busy": "2022-03-13T19:51:05.498942Z",
     "iopub.status.idle": "2022-03-13T19:52:59.647021Z",
     "shell.execute_reply": "2022-03-13T19:52:59.646259Z",
     "shell.execute_reply.started": "2022-03-13T19:51:05.499227Z"
    }
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model1.fit(x_train, \n",
    "                    y_train, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    batch_size=32,\n",
    "                    epochs=50,\n",
    "                    callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:53:18.564456Z",
     "iopub.status.busy": "2022-03-13T19:53:18.564203Z",
     "iopub.status.idle": "2022-03-13T19:53:19.001609Z",
     "shell.execute_reply": "2022-03-13T19:53:19.000721Z",
     "shell.execute_reply.started": "2022-03-13T19:53:18.564425Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.save(\"maghreb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:53:21.802447Z",
     "iopub.status.busy": "2022-03-13T19:53:21.802196Z",
     "iopub.status.idle": "2022-03-13T19:53:21.872869Z",
     "shell.execute_reply": "2022-03-13T19:53:21.871959Z",
     "shell.execute_reply.started": "2022-03-13T19:53:21.802419Z"
    }
   },
   "outputs": [],
   "source": [
    "target_names=np.unique(df['dialect']).tolist()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:53:24.318729Z",
     "iopub.status.busy": "2022-03-13T19:53:24.317978Z",
     "iopub.status.idle": "2022-03-13T19:53:24.332150Z",
     "shell.execute_reply": "2022-03-13T19:53:24.331443Z",
     "shell.execute_reply.started": "2022-03-13T19:53:24.318681Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:53:27.675647Z",
     "iopub.status.busy": "2022-03-13T19:53:27.675176Z",
     "iopub.status.idle": "2022-03-13T19:53:27.683173Z",
     "shell.execute_reply": "2022-03-13T19:53:27.682083Z",
     "shell.execute_reply.started": "2022-03-13T19:53:27.675613Z"
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(np.array(y_test),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification report for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:53:46.045240Z",
     "iopub.status.busy": "2022-03-13T19:53:46.044926Z",
     "iopub.status.idle": "2022-03-13T19:54:31.428862Z",
     "shell.execute_reply": "2022-03-13T19:54:31.427118Z",
     "shell.execute_reply.started": "2022-03-13T19:53:46.045210Z"
    }
   },
   "outputs": [],
   "source": [
    "pred=model1.predict(x_test)\n",
    "print(classification_report(np.argmax(np.array(y_test),axis=1),np.argmax(pred,axis=1), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification report for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:54:31.431010Z",
     "iopub.status.busy": "2022-03-13T19:54:31.430721Z",
     "iopub.status.idle": "2022-03-13T19:54:41.803038Z",
     "shell.execute_reply": "2022-03-13T19:54:41.802229Z",
     "shell.execute_reply.started": "2022-03-13T19:54:31.430967Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_train=model1.predict(x_train)\n",
    "print(classification_report(np.argmax(np.array(y_train),axis=1),np.argmax(pred_train,axis=1), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:56:55.227473Z",
     "iopub.status.busy": "2022-03-13T19:56:55.227209Z",
     "iopub.status.idle": "2022-03-13T19:56:55.234468Z",
     "shell.execute_reply": "2022-03-13T19:56:55.233767Z",
     "shell.execute_reply.started": "2022-03-13T19:56:55.227443Z"
    }
   },
   "outputs": [],
   "source": [
    "a=\"توحشتك\"\n",
    "l=splitolist(a)\n",
    "seq=tokenizer.texts_to_sequences(l)\n",
    "b=[item for sublist in seq for item in sublist]\n",
    "print(b)\n",
    "pad_seq=pad_sequences([b], maxlen=max_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:56:57.849348Z",
     "iopub.status.busy": "2022-03-13T19:56:57.848722Z",
     "iopub.status.idle": "2022-03-13T19:56:57.856530Z",
     "shell.execute_reply": "2022-03-13T19:56:57.855626Z",
     "shell.execute_reply.started": "2022-03-13T19:56:57.849304Z"
    }
   },
   "outputs": [],
   "source": [
    "print(l,seq,pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:57:00.739313Z",
     "iopub.status.busy": "2022-03-13T19:57:00.739040Z",
     "iopub.status.idle": "2022-03-13T19:57:00.790284Z",
     "shell.execute_reply": "2022-03-13T19:57:00.789577Z",
     "shell.execute_reply.started": "2022-03-13T19:57:00.739283Z"
    }
   },
   "outputs": [],
   "source": [
    "out=model1.predict(pad_seq).argmax(axis=1)\n",
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:57:02.948848Z",
     "iopub.status.busy": "2022-03-13T19:57:02.948228Z",
     "iopub.status.idle": "2022-03-13T19:57:02.954048Z",
     "shell.execute_reply": "2022-03-13T19:57:02.953300Z",
     "shell.execute_reply.started": "2022-03-13T19:57:02.948803Z"
    }
   },
   "outputs": [],
   "source": [
    "country_pred=target_names[out[0]]\n",
    "country_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
