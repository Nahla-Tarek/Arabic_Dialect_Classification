{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:10.359940Z",
     "iopub.status.busy": "2022-03-13T18:41:10.359594Z",
     "iopub.status.idle": "2022-03-13T18:41:20.473795Z",
     "shell.execute_reply": "2022-03-13T18:41:20.473006Z",
     "shell.execute_reply.started": "2022-03-13T18:41:10.359853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
      "     |████████████████████████████████| 242 kB 886 kB/s            \n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:20.476885Z",
     "iopub.status.busy": "2022-03-13T18:41:20.476660Z",
     "iopub.status.idle": "2022-03-13T18:41:26.911719Z",
     "shell.execute_reply": "2022-03-13T18:41:26.910903Z",
     "shell.execute_reply.started": "2022-03-13T18:41:20.476848Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import fasttext\n",
    "from nltk.util import ngrams\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,GRU,LSTM,Bidirectional,Dropout,Conv1D,MaxPooling1D,GlobalAveragePooling1D,Flatten,Input\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from gensim.models import word2vec\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import excel file for levant countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:26.913215Z",
     "iopub.status.busy": "2022-03-13T18:41:26.912974Z",
     "iopub.status.idle": "2022-03-13T18:41:36.927209Z",
     "shell.execute_reply": "2022-03-13T18:41:36.926372Z",
     "shell.execute_reply.started": "2022-03-13T18:41:26.913183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens     0\n",
       "dialect    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"../input/data-arabic-dialect/data_levant.xlsx\",index_col=0,\n",
    "              dtype={'tokens': str, 'dialect': str})\n",
    "## check the presence of null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:36.929538Z",
     "iopub.status.busy": "2022-03-13T18:41:36.929290Z",
     "iopub.status.idle": "2022-03-13T18:41:36.949925Z",
     "shell.execute_reply": "2022-03-13T18:41:36.949226Z",
     "shell.execute_reply.started": "2022-03-13T18:41:36.929503Z"
    }
   },
   "outputs": [],
   "source": [
    "## reset index\n",
    "df=df.reset_index()\n",
    "df.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count numbers of sentences that belong to each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:36.951654Z",
     "iopub.status.busy": "2022-03-13T18:41:36.951301Z",
     "iopub.status.idle": "2022-03-13T18:41:37.159777Z",
     "shell.execute_reply": "2022-03-13T18:41:37.158996Z",
     "shell.execute_reply.started": "2022-03-13T18:41:36.951618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PL', 'JO', 'LB', 'SY'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='dialect'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=df['dialect'].value_counts()\n",
    "print(x.index)\n",
    "sns.barplot(x.index,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute the max number of words ( max_length of the sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:37.161165Z",
     "iopub.status.busy": "2022-03-13T18:41:37.160935Z",
     "iopub.status.idle": "2022-03-13T18:41:37.166442Z",
     "shell.execute_reply": "2022-03-13T18:41:37.165582Z",
     "shell.execute_reply.started": "2022-03-13T18:41:37.161129Z"
    }
   },
   "outputs": [],
   "source": [
    "def splitolist(data):\n",
    "    l=data.split(\" \")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:37.168664Z",
     "iopub.status.busy": "2022-03-13T18:41:37.168179Z",
     "iopub.status.idle": "2022-03-13T18:41:37.373539Z",
     "shell.execute_reply": "2022-03-13T18:41:37.372797Z",
     "shell.execute_reply.started": "2022-03-13T18:41:37.168629Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tokens1']=df['tokens'].apply(splitolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:37.375086Z",
     "iopub.status.busy": "2022-03-13T18:41:37.374793Z",
     "iopub.status.idle": "2022-03-13T18:41:37.457229Z",
     "shell.execute_reply": "2022-03-13T18:41:37.456511Z",
     "shell.execute_reply.started": "2022-03-13T18:41:37.375053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length is 68\n"
     ]
    }
   ],
   "source": [
    "max_length=df.tokens1.str.len().max()\n",
    "print(\"max length is\"+\" \"+str(max_length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a corpus of the entire dataset in a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:37.458902Z",
     "iopub.status.busy": "2022-03-13T18:41:37.458489Z",
     "iopub.status.idle": "2022-03-13T18:41:38.830096Z",
     "shell.execute_reply": "2022-03-13T18:41:38.829350Z",
     "shell.execute_reply.started": "2022-03-13T18:41:37.458850Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r'./corpus.txt', 'w', encoding='utf-8') as txtfile:\n",
    "    for i in range(len(df)):\n",
    "        line = df.loc[i,'tokens']\n",
    "        txtfile.write(line)\n",
    "        txtfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train skipgram model on the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:41:38.833499Z",
     "iopub.status.busy": "2022-03-13T18:41:38.833262Z",
     "iopub.status.idle": "2022-03-13T18:43:48.630604Z",
     "shell.execute_reply": "2022-03-13T18:43:48.628659Z",
     "shell.execute_reply.started": "2022-03-13T18:41:38.833465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  27238\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   99377 lr:  0.000000 avg.loss:  1.580775 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE=100\n",
    "model = fasttext.train_unsupervised('./corpus.txt',\n",
    "                                    minCount = 5, \n",
    "                                    model='skipgram',\n",
    "                                    minn = 2,\n",
    "                                    maxn = 5,\n",
    "                                    dim = 100,\n",
    "                                    lr = 0.1,\n",
    "                                    epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:48.632167Z",
     "iopub.status.busy": "2022-03-13T18:43:48.631825Z",
     "iopub.status.idle": "2022-03-13T18:43:49.102925Z",
     "shell.execute_reply": "2022-03-13T18:43:49.102210Z",
     "shell.execute_reply.started": "2022-03-13T18:43:48.632129Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a list of all unique words in the dataset\n",
    "with open(r'./corpus.txt', 'r', encoding=\"utf-8\") as txtfile:\n",
    "    corpus_sentences = txtfile.readlines()\n",
    "    corpus_words = []\n",
    "    for sent in corpus_sentences:\n",
    "        tokenized_sent = sent.split()\n",
    "        for word_ in tokenized_sent:\n",
    "            corpus_words.append(word_)\n",
    "            \n",
    "    corpus_unique_words = list(set(corpus_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert text to numbers using tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:49.105343Z",
     "iopub.status.busy": "2022-03-13T18:43:49.104744Z",
     "iopub.status.idle": "2022-03-13T18:43:53.730251Z",
     "shell.execute_reply": "2022-03-13T18:43:53.729498Z",
     "shell.execute_reply.started": "2022-03-13T18:43:49.105304Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(corpus_unique_words)+1)\n",
    "tokenizer.fit_on_texts(df['tokens'])\n",
    "sequences = tokenizer.texts_to_sequences(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:53.731690Z",
     "iopub.status.busy": "2022-03-13T18:43:53.731437Z",
     "iopub.status.idle": "2022-03-13T18:43:54.327767Z",
     "shell.execute_reply": "2022-03-13T18:43:54.327019Z",
     "shell.execute_reply.started": "2022-03-13T18:43:53.731657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157089 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=max_length,padding='post')  ## padding all the sentences in the dataset to have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create embedding matrix from the trained fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:54.329355Z",
     "iopub.status.busy": "2022-03-13T18:43:54.329122Z",
     "iopub.status.idle": "2022-03-13T18:43:56.181177Z",
     "shell.execute_reply": "2022-03-13T18:43:56.180406Z",
     "shell.execute_reply.started": "2022-03-13T18:43:54.329324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157089/157089 [00:01<00:00, 85358.21it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "embeddings_matrix = np.zeros(shape = (vocab_size , EMBED_SIZE))\n",
    "\n",
    "for word, index in tqdm(tokenizer.word_index.items()):\n",
    "    embeddings_matrix[index] = model.get_word_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:56.182948Z",
     "iopub.status.busy": "2022-03-13T18:43:56.182514Z",
     "iopub.status.idle": "2022-03-13T18:43:56.200659Z",
     "shell.execute_reply": "2022-03-13T18:43:56.199910Z",
     "shell.execute_reply.started": "2022-03-13T18:43:56.182910Z"
    }
   },
   "outputs": [],
   "source": [
    "data_y=pd.get_dummies(df['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:56.202276Z",
     "iopub.status.busy": "2022-03-13T18:43:56.201871Z",
     "iopub.status.idle": "2022-03-13T18:43:56.216781Z",
     "shell.execute_reply": "2022-03-13T18:43:56.216151Z",
     "shell.execute_reply.started": "2022-03-13T18:43:56.202227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JO</th>\n",
       "      <th>LB</th>\n",
       "      <th>PL</th>\n",
       "      <th>SY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JO  LB  PL  SY\n",
       "0   0   0   1   0\n",
       "1   0   0   1   0\n",
       "2   0   0   1   0\n",
       "3   0   0   1   0\n",
       "4   0   0   1   0\n",
       "5   0   0   1   0\n",
       "6   0   0   1   0\n",
       "7   0   0   1   0\n",
       "8   0   0   1   0\n",
       "9   0   0   1   0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:56.218527Z",
     "iopub.status.busy": "2022-03-13T18:43:56.218035Z",
     "iopub.status.idle": "2022-03-13T18:43:57.192268Z",
     "shell.execute_reply": "2022-03-13T18:43:57.191497Z",
     "shell.execute_reply.started": "2022-03-13T18:43:56.218491Z"
    }
   },
   "outputs": [],
   "source": [
    "#split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,data_y, test_size = 0.1, stratify =data_y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:43:57.193971Z",
     "iopub.status.busy": "2022-03-13T18:43:57.193692Z",
     "iopub.status.idle": "2022-03-13T18:44:00.558480Z",
     "shell.execute_reply": "2022-03-13T18:44:00.557787Z",
     "shell.execute_reply.started": "2022-03-13T18:43:57.193936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 18:43:57.267522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:57.365513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:57.366279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:57.367294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-13 18:43:57.368414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:57.369236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:57.369893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:59.306368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:59.307209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:59.307849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-13 18:43:59.308443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "#create a bidirectional LSTM model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_size, EMBED_SIZE, \n",
    "                                weights=[embeddings_matrix], \n",
    "                                input_length=max_length , \n",
    "                                trainable=True)\n",
    "    \n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5000, activation='relu'))\n",
    "    model.add(Dense(len(np.unique(df['dialect'])), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model1 = create_model()\n",
    "tf.keras.backend.clear_session()\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss',mode = 'max',patience=3,verbose=1) #,mode = 'min',callbacks=[early_stop]\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=2)\n",
    "tf.keras.backend.clear_session()\n",
    "# early_stopping = EarlyStopping(monitor= 'val_acc', \n",
    "#                                mode = 'max',\n",
    "#                                patience=30, \n",
    "#                                verbose=1)\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint('levant_dialect_CLASSIFIER',\n",
    "#                                    monitor = 'val_acc', \n",
    "#                                    mode = 'max', \n",
    "#                                    save_best_only=True, \n",
    "#                                    verbose=1)\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate = 0.0001)\n",
    "\n",
    "model1.compile(opt, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:44:00.565006Z",
     "iopub.status.busy": "2022-03-13T18:44:00.562762Z",
     "iopub.status.idle": "2022-03-13T18:44:00.732078Z",
     "shell.execute_reply": "2022-03-13T18:44:00.731442Z",
     "shell.execute_reply.started": "2022-03-13T18:44:00.564964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JO', 'LB', 'PL', 'SY']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['dialect']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:44:00.737636Z",
     "iopub.status.busy": "2022-03-13T18:44:00.735746Z",
     "iopub.status.idle": "2022-03-13T18:47:09.675508Z",
     "shell.execute_reply": "2022-03-13T18:47:09.674781Z",
     "shell.execute_reply.started": "2022-03-13T18:44:00.737599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 18:44:00.862104: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 18:44:04.126507: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3249/3249 [==============================] - 51s 14ms/step - loss: 1.1441 - accuracy: 0.4918 - val_loss: 1.0577 - val_accuracy: 0.5339\n",
      "Epoch 2/50\n",
      "3249/3249 [==============================] - 46s 14ms/step - loss: 0.9958 - accuracy: 0.5683 - val_loss: 0.9916 - val_accuracy: 0.5697\n",
      "Epoch 3/50\n",
      "3249/3249 [==============================] - 46s 14ms/step - loss: 0.9018 - accuracy: 0.6180 - val_loss: 0.9617 - val_accuracy: 0.5867\n",
      "Epoch 4/50\n",
      "3249/3249 [==============================] - 46s 14ms/step - loss: 0.8202 - accuracy: 0.6605 - val_loss: 0.9588 - val_accuracy: 0.5960\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model1.fit(x_train, \n",
    "                    y_train, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    batch_size=32,\n",
    "                    epochs=50,\n",
    "                    callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:47:09.677644Z",
     "iopub.status.busy": "2022-03-13T18:47:09.677002Z",
     "iopub.status.idle": "2022-03-13T18:47:10.115064Z",
     "shell.execute_reply": "2022-03-13T18:47:10.114264Z",
     "shell.execute_reply.started": "2022-03-13T18:47:09.677605Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.save(\"levant.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:47:10.116512Z",
     "iopub.status.busy": "2022-03-13T18:47:10.116256Z",
     "iopub.status.idle": "2022-03-13T18:47:10.220181Z",
     "shell.execute_reply": "2022-03-13T18:47:10.219212Z",
     "shell.execute_reply.started": "2022-03-13T18:47:10.116479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JO', 'LB', 'PL', 'SY']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names=np.unique(df['dialect']).tolist()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:47:10.221952Z",
     "iopub.status.busy": "2022-03-13T18:47:10.221471Z",
     "iopub.status.idle": "2022-03-13T18:47:10.237846Z",
     "shell.execute_reply": "2022-03-13T18:47:10.237027Z",
     "shell.execute_reply.started": "2022-03-13T18:47:10.221914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JO</th>\n",
       "      <th>LB</th>\n",
       "      <th>PL</th>\n",
       "      <th>SY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88631</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76937</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34449</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64094</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61969</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81277</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11549 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       JO  LB  PL  SY\n",
       "88631   0   1   0   0\n",
       "6712    0   0   1   0\n",
       "76937   1   0   0   0\n",
       "34449   0   0   1   0\n",
       "64094   1   0   0   0\n",
       "...    ..  ..  ..  ..\n",
       "61969   1   0   0   0\n",
       "41946   0   0   1   0\n",
       "81277   1   0   0   0\n",
       "70346   1   0   0   0\n",
       "12005   0   0   1   0\n",
       "\n",
       "[11549 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:47:10.239432Z",
     "iopub.status.busy": "2022-03-13T18:47:10.239100Z",
     "iopub.status.idle": "2022-03-13T18:47:25.316956Z",
     "shell.execute_reply": "2022-03-13T18:47:25.316056Z",
     "shell.execute_reply.started": "2022-03-13T18:47:10.239392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(y_test),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification report for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:47:45.412941Z",
     "iopub.status.busy": "2022-03-13T18:47:45.412671Z",
     "iopub.status.idle": "2022-03-13T18:47:47.184207Z",
     "shell.execute_reply": "2022-03-13T18:47:47.182785Z",
     "shell.execute_reply.started": "2022-03-13T18:47:45.412911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          JO       0.52      0.43      0.47      2791\n",
      "          LB       0.64      0.72      0.68      2762\n",
      "          PL       0.62      0.73      0.67      4373\n",
      "          SY       0.51      0.32      0.39      1623\n",
      "\n",
      "    accuracy                           0.60     11549\n",
      "   macro avg       0.57      0.55      0.55     11549\n",
      "weighted avg       0.59      0.60      0.58     11549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=model1.predict(x_test)\n",
    "print(classification_report(np.argmax(np.array(y_test),axis=1),np.argmax(pred,axis=1), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification report for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:47:57.349250Z",
     "iopub.status.busy": "2022-03-13T18:47:57.348705Z",
     "iopub.status.idle": "2022-03-13T18:48:08.477373Z",
     "shell.execute_reply": "2022-03-13T18:48:08.476555Z",
     "shell.execute_reply.started": "2022-03-13T18:47:57.349211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          JO       0.66      0.55      0.60     25113\n",
      "          LB       0.75      0.82      0.79     24853\n",
      "          PL       0.70      0.82      0.75     39360\n",
      "          SY       0.71      0.48      0.57     14611\n",
      "\n",
      "    accuracy                           0.71    103937\n",
      "   macro avg       0.71      0.67      0.68    103937\n",
      "weighted avg       0.71      0.71      0.70    103937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train=model1.predict(x_train)\n",
    "print(classification_report(np.argmax(np.array(y_train),axis=1),np.argmax(pred_train,axis=1), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:51:07.540946Z",
     "iopub.status.busy": "2022-03-13T18:51:07.540169Z",
     "iopub.status.idle": "2022-03-13T18:51:07.547243Z",
     "shell.execute_reply": "2022-03-13T18:51:07.546541Z",
     "shell.execute_reply.started": "2022-03-13T18:51:07.540901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96, 38, 3253, 22169]\n"
     ]
    }
   ],
   "source": [
    "a=\"اصلا هاي مافيها مراجل\"\n",
    "l=splitolist(a)\n",
    "seq=tokenizer.texts_to_sequences(l)\n",
    "b=[item for sublist in seq for item in sublist]\n",
    "print(b)\n",
    "pad_seq=pad_sequences([b], maxlen=max_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:51:09.895557Z",
     "iopub.status.busy": "2022-03-13T18:51:09.895034Z",
     "iopub.status.idle": "2022-03-13T18:51:09.903699Z",
     "shell.execute_reply": "2022-03-13T18:51:09.902912Z",
     "shell.execute_reply.started": "2022-03-13T18:51:09.895524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['اصلا', 'هاي', 'مافيها', 'مراجل'] [[96], [38], [3253], [22169]] [[   96    38  3253 22169     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(l,seq,pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:51:13.689202Z",
     "iopub.status.busy": "2022-03-13T18:51:13.688714Z",
     "iopub.status.idle": "2022-03-13T18:51:13.741522Z",
     "shell.execute_reply": "2022-03-13T18:51:13.740702Z",
     "shell.execute_reply.started": "2022-03-13T18:51:13.689165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=model1.predict(pad_seq).argmax(axis=1)\n",
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T18:51:16.097595Z",
     "iopub.status.busy": "2022-03-13T18:51:16.096951Z",
     "iopub.status.idle": "2022-03-13T18:51:16.103233Z",
     "shell.execute_reply": "2022-03-13T18:51:16.102437Z",
     "shell.execute_reply.started": "2022-03-13T18:51:16.097554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JO'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_pred=target_names[out[0]]\n",
    "country_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
